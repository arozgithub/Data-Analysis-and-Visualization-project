{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj-RRauW65nJ",
        "outputId": "6735fd13-4510-4ae7-be0d-1640d39b7ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.15.2)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.23.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install drivers\n",
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwPVniGi7apD",
        "outputId": "ee28e3dc-6433-4b1a-80ec-ea6f9f563d5f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXj69Atd7dG0",
        "outputId": "c5a6638d-0c50-4fe2-ac1e-004a15badf37"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selenium-related imports\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "# Other imports\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from scipy import stats\n"
      ],
      "metadata": {
        "id": "lT30ReeCSIKD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# will resolve driver compatibility issues\n",
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver\n"
      ],
      "metadata": {
        "id": "HqxXn_ak7jX_"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_Gaming = web_driver()\n",
        "driver_tech = web_driver()\n",
        "driver_fitness = web_driver()\n",
        "driver_Beauty = web_driver()\n",
        "driver_cook = web_driver()\n",
        "driver_travel = web_driver()\n",
        "driver_cars = web_driver()\n",
        "driver_history = web_driver()\n",
        "\n",
        "driver_estate = web_driver()\n",
        "driver_invest = web_driver()\n",
        "driver_DIY = web_driver()"
      ],
      "metadata": {
        "id": "W_Va5wNpFl8y"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_photo = web_driver()"
      ],
      "metadata": {
        "id": "RTUIVoMzUgs7"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GAMING**"
      ],
      "metadata": {
        "id": "cT4x4GJLWMxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_Gaming.get(\"https://www.youtube.com/results?search_query=Gaming+Videos+In+USA\")\n",
        "\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_Gaming = driver_Gaming.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_Gaming:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_Gaming.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "\n",
        "# DataFrame to store the data\n",
        "df = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_Gaming, 10)\n",
        "v_category_Gaming = \"Gaming\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_Gaming.get(x)\n",
        "        v_id_Gaming = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_Gaming = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df.loc[len(df)] = [v_id_Gaming, v_title_Gaming, v_category_Gaming]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_Gaming.quit()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('youtube_videos.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElPbymYz7ydv",
        "outputId": "0a043910-b0a8-4093-90e0-b7af032e97c9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TECH & GADJETS\n"
      ],
      "metadata": {
        "id": "lsafzKxKWa1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_tech.get(\"https://www.youtube.com/results?search_query=latest+technology%2C+gadgets%2C+tech+reviews\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_tech = driver_tech.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_tech:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_tech.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_tech = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_tech, 10)\n",
        "v_category_tech = \"Tech & Gadgets\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_tech.get(x)\n",
        "        v_id_tech = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_tech = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_tech.loc[len(df_tech)] = [v_id_tech, v_title_tech, v_category_tech]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_tech.quit()\n",
        "\n",
        "df_tech.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWGLLm4qV08o",
        "outputId": "885f8d01-2842-436c-cbc2-f622658fc7b8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitness and health"
      ],
      "metadata": {
        "id": "TLQnUCil0TZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_fitness.get(\"https://www.youtube.com/results?search_query=fitness+and+health\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_fitness = driver_fitness.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_fitness:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_fitness.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_fitness = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_fitness, 10)\n",
        "v_category_fitness = \"Fitness & Health\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_fitness.get(x)\n",
        "        v_id_fitness = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_fitness = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_fitness.loc[len(df_fitness)] = [v_id_fitness, v_title_fitness, v_category_fitness]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_fitness.quit()\n",
        "\n",
        "\n",
        "df_fitness.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLvUn22x0xtC",
        "outputId": "1a18f230-4ad1-4bcb-a8fa-d2b6a010277a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beauty & Fashion"
      ],
      "metadata": {
        "id": "59bvoDRG2X8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_Beauty.get(\"https://www.youtube.com/results?search_query=beauty+and+fashion\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_Beauty = driver_Beauty.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_Beauty:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_Beauty.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_beauty = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_Beauty, 10)\n",
        "v_category_Beauty = \"Beauty & Fashion\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_Beauty.get(x)\n",
        "        v_id_Beauty = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_Beauty = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_beauty.loc[len(df_beauty)] = [v_id_Beauty, v_title_Beauty, v_category_Beauty]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_Beauty.quit()\n",
        "\n",
        "\n",
        "df_beauty.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FipVeyA2fI5",
        "outputId": "f9a697f7-7790-45ab-8e89-955855a91dcd"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cooking & Recipies"
      ],
      "metadata": {
        "id": "BWTh-ouV3OMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "driver_cook.get(\"https://www.youtube.com/results?search_query=cooking+recipes+english+\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls =8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_cook = driver_cook.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_cook:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_cook.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_cooking = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_cook, 10)\n",
        "v_category_cook = \"Cooking & Recipies\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_cook.get(x)\n",
        "        v_id_cook = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_cook = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_cooking.loc[len(df_cooking)] = [v_id_cook, v_title_cook, v_category_cook]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_cook.quit()\n",
        "\n",
        "\n",
        "df_cooking.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL8ie2kj3POe",
        "outputId": "bb20d46d-90eb-42db-dda7-0ef27f3873c7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Travel"
      ],
      "metadata": {
        "id": "acPIasVO4GsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_travel.get(\"https://www.youtube.com/results?search_query=Travel+and+Adventure\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_travel = driver_travel.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_travel:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_travel.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_travel = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_travel, 10)\n",
        "v_category_travel = \"Travel & Adventure\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_travel.get(x)\n",
        "        v_id_travel = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_travel = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_travel.loc[len(df_travel)] = [v_id_travel, v_title_travel, v_category_travel]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_travel.quit()\n",
        "\n",
        "\n",
        "df_travel.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3JcGuEs4KVR",
        "outputId": "515cff27-fff3-4c82-c833-670d605958de"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CARS"
      ],
      "metadata": {
        "id": "tw-e_5xP6V80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_cars.get(\"https://www.youtube.com/results?search_query=Automotive+and+Vehicles++Car+Reviews+and+Test+Drives\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_datadriver_cars = driver_cars.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_datadriver_cars:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_cars.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_cars = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_cars, 10)\n",
        "v_category_cars = \"Cars Reviews\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_cars.get(x)\n",
        "        v_id_cars = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_cars = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_cars.loc[len(df_cars)] = [v_id_cars, v_title_cars, v_category_cars]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_cars.quit()\n",
        "\n",
        "\n",
        "df_cars.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf4fkDCw6cAl",
        "outputId": "4d1061b6-f99b-4afb-a7b7-9fca4b2dee87"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Investment"
      ],
      "metadata": {
        "id": "IwrQPDza7bUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_invest.get(\"https://www.youtube.com/results?search_query=Personal+Finance+and+Investing++Stock+Market+Analysis+and+Tips+Cryptocurrency+Trends+and+Advice\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_invest = driver_invest.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_invest:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_invest.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_invest = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_invest, 10)\n",
        "v_category_invest = \"Investments\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_invest.get(x)\n",
        "        v_id_invest = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_invest = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_invest.loc[len(df_invest)] = [v_id_invest, v_title_invest, v_category_invest]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_invest.quit()\n",
        "\n",
        "\n",
        "df_invest.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5epRWEn7tRV",
        "outputId": "85ea189f-4f23-40db-e51f-bba335bcd15e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real Etates"
      ],
      "metadata": {
        "id": "utAkRKHK8Md3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_estate.get(\"https://www.youtube.com/results?search_query=Real+Estate+and+Home+Improvement++Interior+Design+Ideas+Smart+Home+Technology\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_estate = driver_estate.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_estate:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_estate.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_estate = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_estate, 10)\n",
        "v_category_estate = \"Real Estate\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_estate.get(x)\n",
        "        v_id_estate = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_estate = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_estate.loc[len(df_estate)] = [v_id_estate, v_title_estate, v_category_estate]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_estate.quit()\n",
        "\n",
        "\n",
        "df_estate.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaIkkXPd8RDJ",
        "outputId": "7ef8d0a4-d71b-4768-c1c9-e8747ad78366"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Photography"
      ],
      "metadata": {
        "id": "0BLy5SsT8qhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_photo.get(\"https://www.youtube.com/results?search_query=Photography+and+Videography++Photography+Techniques+and+Tips+Video+Editing+Tutorials+Drone+Photography+Portrait+and+Landscape+Photography\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_photo = driver_photo.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_photo:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_photo.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_photo = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_photo, 10)\n",
        "v_category_photo = \"Photography\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_photo.get(x)\n",
        "        v_id_photo = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_photo = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_photo.loc[len(df_photo)] = [v_id_photo, v_title_photo, v_category_photo]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_photo.quit()\n",
        "\n",
        "\n",
        "df_photo.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEDK06qb8tli",
        "outputId": "d239416f-c36a-425e-81e6-7dc995cded31"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### History"
      ],
      "metadata": {
        "id": "dsGdWMef9FAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_history.get(\"https://www.youtube.com/results?search_query=History+and+Archaeology++Historical+Documentaries+Archaeological+Discoveries+Ancient+Civilizations+and+Cultures\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_history = driver_history.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_history:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_history.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_history = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_history, 10)\n",
        "v_category_history = \"History\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_history.get(x)\n",
        "        v_id_history = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_history = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_history.loc[len(df_history)] = [v_id_history, v_title_history, v_category_history]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_history.quit()\n",
        "\n",
        "\n",
        "df_history.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XDFRJ3j9HtA",
        "outputId": "ac1b2730-cb44-467e-fd59-040e54d94991"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DIY & crafts"
      ],
      "metadata": {
        "id": "maeiusuiDvJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver_DIY.get(\"https://www.youtube.com/results?search_query=DIY+and+Crafts*%3A+Do-it-yourself+projects%2C+arts+and+crafts+tutorials%2C+and+creative+ideas\")\n",
        "links = []\n",
        "scroll_pause_time = 2\n",
        "scroll_count = 0\n",
        "max_scrolls = 8  # Maximum number of scrolls\n",
        "\n",
        "while scroll_count < max_scrolls:\n",
        "    # Find video links on the page\n",
        "    user_data_DIY = driver_DIY.find_elements(By.XPATH, '//*[@id=\"video-title\"]')\n",
        "    for i in user_data_DIY:\n",
        "        href = i.get_attribute('href')\n",
        "        # Skip if the link is a YouTube Short\n",
        "        if href and \"/shorts/\" not in href and href not in links:\n",
        "            links.append(href)\n",
        "\n",
        "    # Increase the scroll count\n",
        "    scroll_count += 1\n",
        "\n",
        "    # Scroll down and wait\n",
        "    driver_DIY.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(scroll_pause_time)\n",
        "\n",
        "# Now, `links` contains the links collected from 5 scrolls\n",
        "print(f\"Total links collected: {len(links)}\")\n",
        "# DataFrame to store the data\n",
        "df_DIY = pd.DataFrame(columns=['link', 'title', 'category'])\n",
        "wait = WebDriverWait(driver_DIY, 10)\n",
        "v_category_DIY = \"DIY & crafts\"\n",
        "\n",
        "for x in links:\n",
        "    try:\n",
        "        driver_DIY.get(x)\n",
        "        v_id_DIY = x.split('https://www.youtube.com/watch?v=')\n",
        "        v_title_DIY = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"yt-formatted-string.style-scope.ytd-watch-metadata\"))).text\n",
        "\n",
        "        df_DIY.loc[len(df_DIY)] = [v_id_DIY, v_title_DIY, v_category_DIY]\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while processing URL {x}: {e}\")\n",
        "\n",
        "# Close the WebDriver\n",
        "driver_DIY.quit()\n",
        "\n",
        "\n",
        "df_DIY.to_csv('youtube_videos.csv', mode='a', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3g4SYVOD0OP",
        "outputId": "d845e842-eb4a-4a64-a097-1a5c11ccb1c2"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links collected: 18\n"
          ]
        }
      ]
    }
  ]
}